# **ADR-003: AI-Assisted Grading for Test 2 (Architecture Submission)**

## **Date:**

2025-02-19

## **Status:**

Proposed

## **Context**

Certifiable Inc. is facing a **5-10X increase** in certification requests due to global expansion. **Test 2 (
Architecture Submission)** is currently **manually graded by expert software architects**, requiring an **average of 8
hours per candidate**. This **manual evaluation is unsustainable** at the projected growth rate.

The **challenges** include:

- **Long turnaround times** (1-week grading period).
- **High operational costs** due to expert labor.
- **Scalability issues** as new expert hires require extensive onboarding.
- **Lack of automation** in evaluating architecture quality, which currently depends solely on expert judgment.

The **goal** is to **enhance scalability and efficiency** by integrating **AI-assisted grading** while maintaining **accuracy and credibility**.

## **Decision**

We will implement a **hybrid AI-assisted grading system** for Test 2 that:

### **1. AI-Assisted Grading Using Retrieval-Augmented Generation (RAG)**

- AI extracts **relevant sections** from the candidate’s submission that correspond to specific **grading criteria**.
- AI grades each criterion separately using **LLM-assisted evaluation** with predefined grading rubrics.
- AI confidence scores determine whether human verification is required.

### **2. Hybrid Grading System**

- **Criteria with high-confidence AI grades** are automatically accepted.
- **Criteria with low-confidence AI grades** are sent for **manual expert review**.
- AI can detect **missing elements** (e.g., missing architectural documentation, unclear SLO definitions).
- A **UI tool** is provided for **human evaluators** to refine AI-generated grading criteria and ensure stability.

### **3. Machine Learning-Based Pass/Fail Classification**

- AI uses a **machine learning classifier** (non-generative) to determine final **pass/fail outcomes** based on graded
  criteria.
- The classifier is **continuously trained on expert-graded submissions** for accuracy.

## **Consequences**

### **Positive Outcomes**

✅ **Scalability:** Reduces grading bottlenecks, handling **5-10X candidate growth**.  
✅ **Efficiency:** Cuts manual grading time **by at least 50%**, reducing workload for expert evaluators.  
✅ **Cost Savings:** Reduces dependency on costly manual grading.  
✅ **Faster Feedback:** AI-assisted grading improves **turnaround time** and enhances the **candidate experience**.  
✅ **Consistency:** AI eliminates grading inconsistencies between different human evaluators.

### **Risks & Mitigation**

⚠ **Risk: AI struggles with vague criteria**  
➡ **Mitigation:** Develop a **precise grading criteria tool** to refine AI scoring.

⚠ **Risk: Candidates distrust AI grading**  
➡ **Mitigation:** Keep **human oversight** and **transparency** in grading explanations.

⚠ **Risk: AI bias in grading**  
➡ **Mitigation:** Train AI using a **diverse dataset** and regularly **audit grading outputs**.

## **Next Steps**

- **Develop AI grading models** using RAG-based retrieval and LLM-assisted evaluation.
- **Build UI tools** for expert evaluators to refine AI-generated grading criteria.
- **Pilot AI-assisted grading** on a subset of candidates.
- **Fine-tune AI performance** based on expert feedback.
- **Scale AI-assisted grading** incrementally, ensuring accuracy and fairness.
