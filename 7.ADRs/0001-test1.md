# **ADR-0002: AI-Enhanced Automated Grading for Test 1**

## **Date:**

2025-02-19

## **Status:**

Accepted

## **Context**

Certifiable Inc. is experiencing a **5-10X increase** in certification requests due to global expansion and growing
demand for software architect licensing. The current **manual grading process** for **Test 1 (Aptitude Test)** requires
an average of **3 hours per candidate**, creating a major **scalability challenge**. The company needs a *
*cost-efficient, accurate, and scalable** solution to automate short-answer grading while maintaining **credibility and
fairness**.

Currently:

- **Multiple-choice questions** are **already auto-graded**.
- **Short-answer questions** are **manually graded** by expert software architects, causing delays and high operational
  costs.
- Certifiable Inc. **guarantees a 1-week turnaround** for grading, which is unsustainable at the projected growth.

The **goal** is to leverage **Generative AI** to:

1. **Automate grading** of short-answer responses while ensuring **human oversight**.
2. **Improve efficiency** by reducing expert workload.
3. **Enhance candidate experience** with faster feedback and personalized study recommendations.
4. **Maintain grading accuracy** to protect the company’s reputation.

## **Decision**

We will implement an **AI-assisted grading system** for Test 1, using a **hybrid human-in-the-loop (HITL) approach**.
The solution includes:

### **1. AI-Powered Automated Grading**

- AI models will evaluate **short-answer questions** based on historical expert-graded responses (120,000+ past
  answers).
- AI-generated grades will be **continuously calibrated** against expert evaluations.
- Confidence levels will be assigned to each AI-generated grade.

### **2. Human Oversight & Ground Truth Calibration**

- **Expert reviewers** will manually grade **5% of responses** to create a **ground truth dataset**.
- AI will be **continuously fine-tuned** based on expert feedback to ensure alignment with human grading.
- New or ambiguous questions will be **manually reviewed** before full AI automation.

### **3. Alternative AI-Human Hybrid Model (Fallback Option)**

- If fully automated grading is infeasible for some questions, AI will generate a **grading summary** and **confidence
  score** for human experts to review.
- Experts **validate or adjust** AI-generated grades where necessary.

### **4. Fraud Mitigation & Quality Assurance**

- AI models will be **evaluated for quality of predictions** on the **historical dataset of candidate submissions**.
- Guardrails will be implemented to detect **AI manipulation** or **cheating attempts**.

## **Consequences**

### **Positive Outcomes**

* [X] **Scalability:** AI grading enables **5-10X candidate growth** without hiring more expert graders.

* [X] **Efficiency:** Reduces manual grading workload, **cutting turnaround time from 1 week to near real-time**.

* [X] **Cost Savings:** Saves Certifiable Inc. an estimated **$150–$300 per candidate** in manual grading costs.

* [X] **Improved Candidate Experience:** Instant feedback enhances learning and reduces stress.

* [X] **Consistency & Standardization:** AI eliminates **human grading inconsistencies**.

### **Risks & Mitigation**

**Risk: AI grading inaccuracies**
Mitigation: Continuous **human calibration & monitoring** to maintain grading integrity.

**Risk: Candidate skepticism about AI grading**
Mitigation: Maintain **human oversight**, provide **detailed feedback**, and ensure transparency in grading.

**Risk: AI bias & fairness issues**
Mitigation: Use **diverse training datasets**, implement **bias detection models**, and ensure **regular audits**.

## **Next Steps**

- **Develop AI models** based on existing graded datasets.
- **Pilot AI grading** with a subset of candidates.
- **Evaluate AI performance** and fine-tune as needed.
- **Scale AI grading incrementally**, starting with high-confidence responses.
- **Monitor candidate feedback** and refine the user experience.
